---
title: "Content analysis"
author: "Jae Yeon Kim"
output:
html_document: 
  toc: true
  theme: united
---

## 0. Setup 

```{r}

# Clean up the environment

rm(list = ls())

# Import libraries (adapted from this link: https://stackoverflow.com/questions/4090169/elegant-way-to-check-for-missing-packages-and-install-them)

if (!require("pacman")) install.packages("pacman")
pacman::p_load(
        tidyverse, # for the tidyverse framework
        irr, # for calculating inter-coder reliability score
        corrplot, # for visualizing correlation coefficients
        ggpubr, # for arranging ggplots   
        ggthemes # for fancy ggplot themes
)

source("/home/jae/content-analysis-for-evaluating-ML-performances/functions/theme_publications.r")

theme_set(theme_Publication(14))

```

## 1. Importing files 


```{r}

# Training data for classifying articles from Asian American newspapers 
training_asian <- read_csv("/home/jae/content-analysis-for-evaluating-ML-performances/raw_data/training_asian.csv") %>%
  dplyr::select(-contains("Notes")) %>%
  mutate(linked_progress_gran = ifelse(Promoting_collective_gains_A + Promoting_collective_gains_B >= 1, 1, 0),
         linked_hurt_gran = ifelse(Preventing_collective_losses_A + Preventing_collective_losses_B >= 1, 1, 0),
         linked_progress = ifelse(Promoting_collective_gains_A == Promoting_collective_gains_B, 1, 0),
         linked_hurt = ifelse(Preventing_collective_losses_A == Preventing_collective_losses_B, 1, 0))

# Training data for classifying articles from African American newspapers
training_black <- read_csv("/home/jae/content-analysis-for-evaluating-ML-performances/raw_data/training_black.csv") %>%
  dplyr::select(-contains("Notes")) %>%
  mutate(linked_progress_gran = ifelse(Promoting_collective_gains_A + Promoting_collective_gains_B >= 1, 1, 0),
         linked_hurt_gran = ifelse(Preventing_collective_losses_A + Preventing_collective_losses_B >= 1, 1, 0),
         linked_progress = ifelse(Promoting_collective_gains_A == Promoting_collective_gains_B, 1, 0),
         linked_hurt = ifelse(Preventing_collective_losses_A == Preventing_collective_losses_B, 1, 0))

# Dimensions 
dim(training_asian)
dim(training_black)

# Variable names
names(training_asian) == names(training_black)

```

## 2. Descriptive statistics 

### 2.1. Merging

```{r}

# Wrangling 

df <- bind_rows(
  mutate(training_asian, group = "Asian Americans"),
  mutate(training_black, group = "African Americans"))

```

### 2.2. Data visualization 

```{r}

df %>%
  gather(type, value, linked_progress, linked_hurt) %>%
  group_by(group, type) %>%
  summarise(mean = mean(value), # summarize mean, standard deviation, and n 
            sd = sd(value),
            n = n()) %>%
  mutate(se = sd / sqrt(n), # calculate standard errors and confidence intervals 
         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,
         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se) %>%
  ggplot(aes(x = fct_reorder(type, mean), y = mean, ymax = upper.ci, ymin = lower.ci, col = group)) +
    geom_pointrange() + # point estimates plus confidence intervals 
    theme_clean() +
    coord_flip() +
    labs(y= "Percentages of Agreement", x = "Type",
         title = "Percentages of Agreement",
         subtitle = "1: Perfect/Half agreement, 0: Zero agreement",
         caption = "Ethnic NewsWatch",
         col = "Group") +
    theme(text = element_text(size = 15)) # large font size 

ggsave("/home/jae/content-analysis-for-evaluating-ML-performances/outputs/content_analysis_agreement.png")

```

#### 2.2.2. Checking the data balance 

```{r}

ggarrange(
df %>%
  group_by(group, linked_progress) %>%
  add_count() %>%
  ggplot(aes(x = as.factor(linked_progress), y = n, fill = group)) +
    geom_col(position = "dodge") +
    labs(x = "Values", y = "N",
         title = "Linked Progress",
         subtitle = "Yes = 1, No = 0",
         fill = "Group") +
    theme_clean(),

df %>%
  group_by(group, linked_hurt) %>%
  add_count() %>%
  ggplot(aes(x = as.factor(linked_hurt), y = n, fill = group)) +
    geom_col(position = "dodge") +     
    labs(x = "Values", y = "Freq",
         title = "Linked Hurt",
         subtitle = "Yes = 1, No = 0",
         fill = "Group") +
    theme_clean(), common.legend = TRUE)

ggsave("/home/jae/content-analysis-for-evaluating-ML-performances/outputs/content_analysis_n_count.png")
```

## 3. Analyzing Inter-coder agreement (percentage) and reliability scores

### 3.1. Creating functions

```{r}

extract_kappa <- function(data){
  
 kappa_progress  <- data %>%
      dplyr::select(contains("gains")) %>%
      kappa2("squared")
 
 kappa_hurt <- data %>%
      dplyr::select(contains("losses")) %>%
      kappa2("squared")
 
 data.frame("kappa_progress" = kappa_progress$value, 
            "kappa_hurt" = kappa_hurt$value)
}

extract_agreement <- function(data){
  
 agreement_progress  <- data %>%
      dplyr::select(contains("gains")) %>%
      agree()
 
 agreement_hurt <- data %>%
      dplyr::select(contains("losses")) %>%
      agree()
 
 data.frame("agreement_progress" = agreement_progress$value/100, 
            "agreement_hurt" = agreement_hurt$value/100)
}

```

### 3.2. Applying the functions to each group 

```{r}

irr_summary <- bind_rows(
mutate(
  bind_cols(training_asian %>%
  extract_kappa(),
          training_asian %>%
  extract_agreement()), group = "Asian Americans"),
mutate(
  bind_cols(training_black %>%
  extract_kappa(),
          training_black %>%
  extract_agreement()), group = "African Americans"))

write.csv(irr_summary, "/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/irr_summary.csv")

```

### 3.3. Visualizing agreement and Kappa  

```{r}

irr_summary %>%
  gather(type, value, kappa_progress:agreement_hurt) %>% 
  ggplot(aes(x = fct_reorder(type, value), y = value, fill = group)) +
    geom_col(position = "dodge") +
    coord_flip() +
    labs(y= "Intercorder Reliability Scores", x = "Linked Fate Type",
         title = "Content Analysis Results",
         subtitle = "Kappa = Cohen's Kappa. Inter-coder reliability score.",
         caption = "Ethnic NewsWatch",
         fill = "Group") +
    theme_clean() + # five thirty eight theme 
    theme(text = element_text(size = 15)) # large font size 

ggsave("/home/jae/content-analysis-for-evaluating-ML-performances/outputs/content_analysis_kappa.png")

```

## 4. Additional exploratory data analyses 

### 4.1. Visualizing the frequency of agreed topics 

```{r}

# Asian Americans
train_asian_plot <- training_asian %>%
  rename(Linked_progress = linked_progress_gran) %>%
  rename(Linked_hurt = linked_hurt_gran) %>%
  gather("linked_fate", "value", Linked_progress, Linked_hurt) %>%
  filter(value == 1) %>%
  filter(Topics_C != "Mismatch") %>%
  filter(Topics_C != "Others") %>%
  group_by(linked_fate) %>%
  count(Topics_C) %>%
  spread(linked_fate, n) %>%
  mutate(Linked_progress = ifelse(is.na(Linked_progress), 0, Linked_progress),
         Linked_hurt = ifelse(is.na(Linked_hurt), 0, Linked_hurt)) %>%
  mutate(difference = Linked_progress - Linked_hurt) %>%
  ggplot(aes(x = fct_reorder(Topics_C, difference), y = difference)) +
    geom_col(position = "dodge") +
    coord_flip() +
    labs(x = "Topics", y = "Difference = N of Linked Progress - N of Linked Hurt", title = "Asian Americans") +
    ylim(c(-30,20))

# African Americans
train_black_plot <- training_black %>%
  rename(Linked_progress = linked_progress_gran) %>%
  rename(Linked_hurt = linked_hurt_gran) %>%
  gather("linked_fate", "value", Linked_progress, Linked_hurt) %>%
  filter(value == 1) %>%
  filter(Topics_C != "Mismatch") %>%
  group_by(linked_fate) %>%
  count(Topics_C) %>%
  spread(linked_fate, n) %>%
  mutate(Linked_progress = ifelse(is.na(Linked_progress), 0, Linked_progress),
         Linked_hurt = ifelse(is.na(Linked_hurt), 0, Linked_hurt)) %>%
  mutate(difference = Linked_progress - Linked_hurt) %>%
  ggplot(aes(x = fct_reorder(Topics_C, difference), y = difference)) +
    geom_col(position = "dodge") +
    coord_flip() +
    labs(x = "Topics", y = "Difference = N of Linked Progress - N of Linked Hurt", title = "African Americans")+
    ylim(c(-30,20))

ggarrange(train_asian_plot, train_black_plot, ncol = 1, nrow = 2, common.legend = TRUE)

ggsave("/home/jae/content-analysis-for-evaluating-ML-performances/outputs/content_analysis_topics.png", height = 10)

```

### 4.2. Visualizing correlation coefficients between the two concepts

```{r}

df %>%
  select(linked_progress, linked_hurt, group) %>%
  group_by(group) %>%
  summarize(corr = cor(linked_progress, linked_hurt), method = "Pearson") %>%
  ggplot(aes(x = fct_reorder(group, corr), y = corr)) +
    geom_col() +
    labs(title = "Correlation Coefficients",
         y = "Pearson Correlation coefficient",
         x = "Group",
         caption = "Ethnic NewsWatch") +
    theme_clean() +
    geom_col() +
    coord_flip()

ggsave("/home/jae/content-analysis-for-evaluating-ML-performances/outputs/corr_analysis.png")

```


## 5. Reading texts 

- Merging the text files with the content analysis 

```{r}

sample_asian <- read_rds("/home/jae/content-analysis-for-evaluating-ML-performances/raw_data/sample_asian.rds")
sample_black <- read_rds("/home/jae/content-analysis-for-evaluating-ML-performances/raw_data/sample_black.rds")

sample_asian <- bind_cols(sample_asian, training_asian %>% select(linked_progress, linked_hurt, linked_progress_gran, linked_hurt_gran, Topics_C))
sample_black <- bind_cols(sample_black, training_black %>% select(linked_progress, linked_hurt, linked_progress_gran, linked_hurt_gran, Topics_C))

```

- Reading extreme cases 

```{r}

sample_asian_text <- sample_asian %>%
  filter(Topics_C == "Political representation" & linked_progress_gran == 1 & linked_hurt_gran == 0) %>%
  select(date, source, text) 

sample_black_text <- sample_black %>%
  filter(Topics_C == "Criminal justice" & linked_hurt_gran == 1 & linked_progress_gran == 0) %>%
  select(date, source, text) 

```

## 6. Exporting non-duplicated files 

```{r}

# Non-duplicated 
sample_asian <- sample_asian[!duplicated(sample_asian$text),]
sample_black <- sample_black[!duplicated(sample_black$text),]

# Check 
1008 - nrow(sample_asian)
1008 - nrow(sample_black)

# Export 
write.csv(sample_asian, "/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/sample_asian.csv")
write.csv(sample_black, "/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/sample_black.csv")

```

