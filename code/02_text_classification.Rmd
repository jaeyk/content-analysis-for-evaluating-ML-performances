---
title: "Text classification"
author: "Jae Yeon Kim"
output:
html_document: 
  toc: true
  theme: united
---

Resources 
- https://www.hvitfeldt.me/blog/text-classification-with-tidymodels/#introduction
- https://juliasilge.com/blog/tidy-text-classification/
- http://www.rebeccabarter.com/blog/2019-06-06_pre_processing/
- https://www.benjaminsorensen.me/post/modeling-with-parsnip-and-tidymodels/
- https://towardsdatascience.com/modelling-with-tidymodels-and-parsnip-bae2c01c131c
- https://www.hvitfeldt.me/blog/authorship-classification-with-tidymodels-and-textrecipes/
- https://cran.r-project.org/web/packages/text2vec/vignettes/text-vectorization.html
- https://stackoverflow.com/questions/43744399/can-i-get-classification-accuracy-and-cohens-kappa-from-glm-results
- http://www.sthda.com/english/articles/36-classification-methods-essentials/149-penalized-logistic-regression-essentials-in-r-ridge-lasso-and-elastic-net/
- http://fisher.stats.uwo.ca/faculty/aim/2019/9850/RNotebooks/21_CaravanRevisited_Apr7.html
- https://fderyckel.github.io/2016-12-07-Texts_Classification_in_R/
- https://cfss.uchicago.edu/notes/supervised-text-classification/
- https://abndistro.com/post/2019/02/17/text-classification-using-text2vec/
- https://www.kirenz.com/post/2019-09-16-r-text-mining/

## 0. Setup 

I tweaked the global option of the R Markdown to enlarge figures produced by ggplot2.

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width = 12, fig.height = 8, 
                      echo = FALSE, warning = FALSE, message = FALSE) # global setting for enlarging image size
```

```{r}

# Clean up the environment

rm(list = ls())

# Import libraries (adapted from this link: https://stackoverflow.com/questions/4090169/elegant-way-to-check-for-missing-packages-and-install-them)

if (!require("pacman")) install.packages("pacman")
pacman::p_load(
        tidyverse, # for the tidyverse framework
        tidymodels, # for tidy modeling  
        caret, # for ML
        pROC, # for ROC
        parsnip, # for modeling
        tidytext, # for text analysis in a tidy way
        lubridate, # for date manipulation
        textrecipes, # for preprocessing text data
        text2vec, # for preprocessing text data
        stopwords, # for stopwords
        tokenizers, # for tokenizing
        textclean, # for cleaning text
        hunspell, # for cleaning text 
        textshape, # for cleaning text
        SuperLearner, # for ensemble models 
        tm, # for cleaning text 
        tidyr, # for creating tidy data
        furrr, # for applying mapping functions
        ggpubr, # for arranging ggplot2 
        ggthemes, # for fancy ggplot themes
        glmnet, # for logistic regression classifier
        randomForest, # for random forest classifier
        rpart, # for recursive partitioning
        caTools, # for ML
        splitstackshape, # for stratified random sampling
        DMwR, # for daealing with imbalanced classes 
        imbalance, # for dealing wiht imbalanced classes
        broom, # for visualizing coefficients
        yardstick, # for ML measures
        superml # for building ML like using scikit-learn in R
)

```

https://www.alexpghayes.com/blog/implementing-the-super-learner-with-tidymodels/

## 1. Importing files 

I skipped the first and second column (author) of all of these files because they are not informative. The original unlabeled data have linked progress and linked hurt columns (all NAs). I removed them too for the same reason.

```{r}

# Labeled data 

labeled_asian <- read_csv("/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/sample_asian.csv")[,-c(1,2)]
labeled_black <- read_csv("/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/sample_black.csv")[,-c(1,2)]

# Unlabeled data 

unlabeled_asian <- read_csv("/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/unlabeled_asian.csv")[,-c(1,2,7,8)]
unlabeled_black <- read_csv("/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/unlabeled_black.csv")[,-c(1,2,7,8)]

# From content analysis: Correlation coefficients and Kappa statistics 

irr_summary <- read_csv("/home/jae/content-analysis-for-evaluating-ML-performances/outputs/irr_summary.csv")[,-1]

names(unlabeled_asian)
```

## 2. Cleaning text

### 2.1. Creating my custom text clean function 

```{r}

clean_text <- function(document){
    document %>% 
    tolower() %>% # low key 
    # Some noisy patterns in the text 
    gsub("[\r?\n]", " ", .) %>% # remove \n
    gsub("[\"]", " ", .) %>%
    gsub("[.]", "", .) %>%
    gsub("[,]", " ", .) %>%
    gsub("[-]", "", .) %>%
    gsub("[']", "", .) %>%
    gsub("[/]", " ", .) %>%
    gsub("[/]", " ", .) %>%
    gsub("[(]", " ", .) %>%
    gsub("[)]", " ", .) %>%
    gsub("[;]", " ", .) %>%
    trimws() # remove whitespace 
}

```

### 2.2. Applying the function to each data 

```{r}
  
labeled_asian$text <- clean_text(labeled_asian$text) 
labeled_black$text <- clean_text(labeled_black$text) 

labeled_asian$text[5]
```

## 3. Feature engineering (bag of words)

### 3.1. Creating my custom function for feature engineering

```{r}

vectorize_train_test <- function(dataset, measure){

# Add doc ID (this var turns out to be very important for sorting)

dataset <- dataset %>%
  mutate(doc_id = row_number())

# Define stopwords

stopword <- as_tibble(stopwords::stopwords("en")) 
stopword <- rename(stopword, word=value) 

# Tokenize and reduce noisy tokens (=stopwords)

tidy_docs <- dataset %>%
  unnest_tokens(word, text) %>%
  anti_join(stopword, by = 'word') %>% # remove stopwords 
  group_by(word) %>% 
  filter(n() >= 20) %>% # remove words appeared less than 20 times
  ungroup()
  
# Create two random samples (testing and training sets) stratifying on year variable (the exactly same variable I used to create a list of documents for content anlysis)

set.seed(1234) # for reproducibility

docs_split <- dataset %>%
  initial_split(prop = 0.8, strata = year) # year: stratifying variable

train_data <- training(docs_split) # Training set

test_data <- testing(docs_split) # Testing set

# Turning training and test data from a tidy data structure into a sparse matrix 

train_matrix <- tidy_docs %>%
  count(doc_id, word) %>%
  inner_join(train_data, by = "doc_id") %>%
  cast_sparse(doc_id, word, n) 

print(paste("N of observations in the training set:", dim(train_matrix)[1], "," , "N of features in the training set:", dim(train_matrix)[2]))

test_matrix <- tidy_docs %>%
  count(doc_id, word) %>%
  inner_join(test_data, by = "doc_id") %>%
  cast_sparse(doc_id, word, n) 

print(paste("N of observations in the testing set:", dim(test_matrix)[1], "," , "N of features in the testing set:", dim(test_matrix)[2]))

################### Set response variable of the training set ####################

print(names(dataset))

# Extract the response variable from the dataset by matching doc ID between them 

train_joined <- tibble(doc_id = as.integer(rownames(train_matrix))) %>%
  left_join(dataset[,c(measure,7)])

train_response <- train_joined[2] == 1

################### Set response variable of the testing set ####################

# Extract the response variable from the dataset by matching doc ID between them 

test_joined <- tibble(doc_id = as.integer(rownames(test_matrix))) %>%
  left_join(dataset[,c(measure,7)])

# This is the target 

test_response <- test_joined[2] == 1

result <- list(train_matrix, test_matrix, train_response, test_response)

return(result)

}

```

### 3.2. Applying the function to each data 

```{r}

# 5 is the index number of linked progress column and 6 is the index number of linked hurt.

asian_lp <- vectorize_train_test(labeled_asian, 5)

asian_lh <- vectorize_train_test(labeled_asian, 6)

black_lp <- vectorize_train_test(labeled_black, 5)

black_lh <- vectorize_train_test(labeled_black, 6)

```

## 3. Model building and testing  

### 3.1. Creating my custom function for model building and testing 

```{r}

build_test <- function(dataset){
    
################## DATA SETUP #######################
  
train_matrix <- dataset[[1]] %>% as.matrix() %>% as.data.frame() # Originally, it was a sparse matrix.

test_matrix <- dataset[[2]] %>% as.matrix %>% as.data.frame() # Originally, it was a sparse matrix.

train_response <- dataset[[3]] %>% as.factor() # Originally, it was matrix.

test_response <- dataset[[4]] %>% as.factor() # Originally, it was matrix.

levels(train_response) <- c("No", "Yes") # Rename factor levels 

levels(test_response) <- c("No", "Yes") # Rename factor levels

print("Data setup is okay.")

################# TRAIN CONTROL SETUP ##################

# This setup defines measures of performance.

set.seed(1234)

trctrl <- trainControl(method = "cv", number = 10) # 10-fold CV

print("Train control setup is okay.")

################# NAIVE BAYES ####################

nb_mod <- train(x = train_matrix,
                y = train_response,
                method = "naive_bayes",
                trControl = trctrl,
                tuneGrid = data.frame(laplace = 0,
                                      usekernel = FALSE,
                                      adjust = FALSE))

nb_pred <- predict(nb_mod,
                   newdata = test_matrix)

nb_cm <- confusionMatrix(nb_pred, test_response)

print("Naive Bayes model works.")

```

```{r}
################# PENALIZED LOGIT ####################

lasso_mod <- train(x = data.matrix(train_matrix),
                  y = train_response, 
                  method = "plr",
                  trControl = trctrl)

lasso_pred <- predict(lasso_mod,
                           newdata = data.matrix(test_matrix))
  
lasso_cm <- confusionMatrix(lasso_pred, test_response)

print("Lasso works.")


```

```{r}
################# LOGIT BOOST ####################

logitboost_mod <- train(x = train_matrix,
                        y = train_response,
                        method = "LogitBoost",
                        trControl = trctrl)

logitboost_pred <- predict(logitboost_mod,
                           newdata = test_matrix)

logitboost_cm <- confusionMatrix(logitboost_pred, test_response)

print("Logit boost works.")

################# RANDOM FOREST ####################

rf_mod <- train(x = train_matrix, 
                y = train_response, 
                method = "ranger",
                trControl = trctrl,
                tuneGrid = data.frame(mtry = floor(sqrt(dim(train_matrix)[2])),
                                      splitrule = "gini",
                                      min.node.size = 1))

rf_pred <- predict(rf_mod,
                   newdata = test_matrix)

rf_cm <- confusionMatrix(rf_pred, test_response)

print("Random forest works.")

################# BINDING RESULTS ####################

# Accuracy 
acu_results <- rbind(
  nb_cm$overall,
  lasso_cm$overall,
  logitboost_cm$overall,
  rf_cm$overall
  ) %>%
  as.data.frame() %>%
  mutate(model = c("Naive-Bayes", "Penalized logit", "LogitBoost", "Random forest"))

# Balanced accuracy 

balanced_acu_results <- c(
  bal_accuracy_vec(nb_pred, test_response),
  bal_accuracy_vec(lasso_pred, test_response),
  bal_accuracy_vec(logitboost_pred, test_response),
  bal_accuracy_vec(rf_pred, test_response))

# Putting all together as a dataframe

mods <- list(nb_mod, lasso_mod, logitboost_mod, rf_mod)
  
metrices <- data.frame(acu = acu_results$Accuracy,
                          kappa = acu_results$Kappa,
                          balanced_acu = balanced_acu_results) %>%
  mutate(model = c("Naive-Bayes", "Penalized logit", "LogitBoost", "Random forest")) 

mod_results <- list(mods, metrices)

return(mod_results)}

```

### 3.2. Extracting and visualizing the model outcomes

```{r}

# Using multiple cores 
# doMC::registerDoMC(cores = 6)

##### Extract outcomes #####

asian_lp_model <- build_test(asian_lp)

asian_lh_model <- build_test(asian_lh)

black_lp_model <- build_test(black_lp)

black_lh_model <- build_test(black_lh)


##### Extract metrices #####

asian_lp_metrices <- asian_lp_model[2] %>% as.data.frame()

asian_lh_metrices <- asian_lh_model[2] %>% as.data.frame()

black_lp_metrices <- black_lp_model[2] %>% as.data.frame()

black_lh_metrices <- black_lh_model[2] %>% as.data.frame()

```

```{r}

all_model <- bind_rows(mutate(asian_lp_metrices, group = "Asian_Americans", type = "Linked_progress"),
          mutate(asian_lh_metrices, group = "Asian_Americans", type = "Linked_hurt"),
          mutate(black_lp_metrices, group = "African_Americans", type = "Linked_progress"),
          mutate(black_lh_metrices, group = "African_Americans", type = "Linked_hurt"))

numerify <- function(data){
  data %>% unlist() %>% as.numeric()
}

irr_resummary <- data.frame(content_kappa = c(numerify(irr_summary[1:2, 2]), numerify(irr_summary[1:2, 3])),
                            content_agreement = c(numerify(irr_summary[1:2, 4]), numerify(irr_summary[1:2, 5])),
                            type = c("Linked_progress", "Linked_hurt", "Linked_progress", "Linked_hurt"),
                            group = c("Asian_Americans", "Asian_Americans", "African_Americans", "African_Americans")
)

merged_model <- all_model %>% right_join(irr_resummary) 

```

```{r}

accu_plot <- merged_model %>%
  gather(metrices, performance, acu, balanced_acu) %>%
  ggplot(aes(x = fct_reorder(model, performance), y = performance, fill = metrices)) +
    geom_col(position = "dodge") +
    geom_hline(aes(yintercept = content_agreement), linetype = "dashed") +
    facet_grid(type~group) +
    theme_base() +
    labs(title = "Accuracy", x = "Model", y = "Performance (%)") +
    coord_flip()

kappa_plot <- merged_model %>%
  ggplot(aes(x = fct_reorder(model, kappa), y = kappa)) +
    geom_col(position = "dodge") +
    geom_hline(aes(yintercept = content_kappa), linetype = "dashed") +
    facet_grid(type~group) +
    theme_base() +
    labs(title = "Reliability", x = "Model", y = "Performance (%)") +
    coord_flip()

ggarrange(accu_plot, kappa_plot, ncol = 1, nrow = 2)

ggsave("/home/jae/content-analysis-for-evaluating-ML-performances/outputs/ml_performance.png")

```

## 4. Applying to the unlabeled data

### 4.1. Building a prediction function 

```{r}

extract_feature <- function(dataset){
 
data_counts <- unnest_tokens(dataset, word, text) %>%
  count(id, word, sort = TRUE) 

print("Data count works.")

words_10 <- data_counts %>%
  group_by(word) %>%
  summarise(n = n()) %>% 
  filter(n >= 10) %>%
  select(word)

print("Word 20 is working fine, too.")

data_dtm <- data_counts %>%
  right_join(words_10, by = "word") %>%
  bind_tf_idf(word, id, n) %>%
  cast_dtm(id, word, tf_idf)

print("Matrix transformation is complete.")

test_matrix <- data_dtm %>% as.matrix() %>% as.data.frame()
  
return(test_matrix)
}

```

```{r}

unlabeled_asian$text <- clean_text(unlabeled_asian$text)
#unlabeled_black$text <- clean_text(unlabeled_black$text)

asian_dtm <- extract_feature(unlabeled_asian)
#black_dtm <- extract_feature(unlabeled_black)

asian_lp_preds <- predict(asian_lp_model[[1]][[3]], asian_dtm)

asian_lh_preds <- predict(asian_lh_model[[1]][[3]], asian_dtm)

#black_lp_preds <- predict(black_lp_model[[1]][[3]], black_dtm)

#black_lh_preds <- predict(black_lh_model[[1]][[3]], black_dtm)

sum(as.numeric(as.character(asian_lp_preds)))
```

## 5. Exporting results as a csv file 

```{r}

```

