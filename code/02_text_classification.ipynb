{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries \n",
    "\n",
    "\n",
    "Import only relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jae/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/jae/anaconda3/lib/python3.7/site-packages (3.4.5)\n",
      "Requirement already satisfied: six in /home/jae/anaconda3/lib/python3.7/site-packages (from nltk) (1.12.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jae/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Numpy and Pandas \n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Data visualization \n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# REGEX and NLP\n",
    "\n",
    "import re\n",
    "import string\n",
    "!pip install nltk\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# ML\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB # Naive-Bayes\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression # Linear models\n",
    "from xgboost import XGBClassifier # Xgboost\n",
    "\n",
    "################### Validation ######################\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import LeavePOut\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "################### Vectorizer ######################\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "################### Model evals #####################\n",
    "from sklearn.metrics import accuracy_score # Accuracy score\n",
    "from sklearn.metrics import balanced_accuracy_score # Balanced accuracy score\n",
    "from sklearn.metrics import cohen_kappa_score # Cohen's Kappa score\n",
    "\n",
    "################### Imbalanced data #####################\n",
    "from sklearn.utils import resample # for resampling\n",
    "\n",
    "# Interface\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file path\n",
    "\n",
    "# root = tk.Tk()\n",
    "# root.withdraw()\n",
    "\n",
    "# file_path = filedialog.askopenfilename()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The labeled data \n",
    "\n",
    "asian_sample = pd.read_csv(\"/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/sample_asian.csv\")\n",
    "black_sample = pd.read_csv(\"/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/sample_black.csv\")\n",
    "\n",
    "# The unlabeled data\n",
    "\n",
    "asian_unlabeled = pd.read_csv(\"/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/unlabeled_asian.csv\")\n",
    "black_unlabeled = pd.read_csv(\"/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/unlabeled_black.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine files. As they all have similar structures, taking a look at one of these files is enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>linked_progress</th>\n",
       "      <th>linked_hurt</th>\n",
       "      <th>linked_progress_gran</th>\n",
       "      <th>linked_hurt_gran</th>\n",
       "      <th>Topics_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Lopez, Flora</td>\n",
       "      <td>1976-04-30</td>\n",
       "      <td>International Examiner</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\nS.P.I.C.E. is a nutritional pr...</td>\n",
       "      <td>1976</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1976-09-30</td>\n",
       "      <td>International Examiner</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\nCommunity control rather than ...</td>\n",
       "      <td>1976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1976-06-30</td>\n",
       "      <td>International Examiner</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\"Peasants of the Second Fortre...</td>\n",
       "      <td>1976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Chin, Doug</td>\n",
       "      <td>1976-10-31</td>\n",
       "      <td>International Examiner</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\nMuch of what is now the Intern...</td>\n",
       "      <td>1976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Housing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Chow, Ron</td>\n",
       "      <td>1976-02-29</td>\n",
       "      <td>International Examiner</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\nInternational District Housing...</td>\n",
       "      <td>1976</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Housing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        author        date                  source  \\\n",
       "0           1  Lopez, Flora  1976-04-30  International Examiner   \n",
       "1           2           NaN  1976-09-30  International Examiner   \n",
       "2           3           NaN  1976-06-30  International Examiner   \n",
       "3           4    Chin, Doug  1976-10-31  International Examiner   \n",
       "4           5     Chow, Ron  1976-02-29  International Examiner   \n",
       "\n",
       "                                                text  year  linked_progress  \\\n",
       "0  \\n\\n\\n\\n\\n\\n\\n\\nS.P.I.C.E. is a nutritional pr...  1976                1   \n",
       "1  \\n\\n\\n\\n\\n\\n\\n\\nCommunity control rather than ...  1976                0   \n",
       "2  \\n\\n\\n\\n\\n\\n\\n\\n\"Peasants of the Second Fortre...  1976                0   \n",
       "3  \\n\\n\\n\\n\\n\\n\\n\\nMuch of what is now the Intern...  1976                0   \n",
       "4  \\n\\n\\n\\n\\n\\n\\n\\nInternational District Housing...  1976                1   \n",
       "\n",
       "   linked_hurt  linked_progress_gran  linked_hurt_gran  Topics_C  \n",
       "0            0                     1                 0  Mismatch  \n",
       "1            0                     0                 0  Mismatch  \n",
       "2            0                     0                 0      Arts  \n",
       "3            0                     0                 0   Housing  \n",
       "4            0                     1                 0   Housing  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First five rows\n",
    "\n",
    "asian_sample.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select only relevant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the first column\n",
    "\n",
    "## Seen \n",
    "\n",
    "asian_sample = asian_sample.drop(['Unnamed: 0'], axis = 1)\n",
    "black_sample = black_sample.drop(['Unnamed: 0'], axis = 1)\n",
    "\n",
    "# An alternative way of doing this is asian_sample = asian_sample[['col1', 'col2']] \n",
    "\n",
    "## Unseen \n",
    "\n",
    "asian_unlabeled = asian_unlabeled.drop(['Unnamed: 0'], axis = 1)\n",
    "black_unlabeled = black_unlabeled.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert date column into datetime. This new data type allows us to extract some useful information from the column. For instance, `asian_samplep['date'].year` returns years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Seen data \n",
    "asian_sample[\"date\"] = pd.to_datetime(asian_sample[\"date\"])\n",
    "black_sample[\"date\"] = pd.to_datetime(black_sample[\"date\"])\n",
    "\n",
    "# Unseen data \n",
    "asian_unlabeled[\"date\"] = pd.to_datetime(asian_unlabeled[\"date\"])\n",
    "black_unlabeled[\"date\"] = pd.to_datetime(black_unlabeled[\"date\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the balance of target values: **imbalanced**. I will use a resampling method (upsampling/oversampling) to address this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    920\n",
       "1     66\n",
       "Name: linked_progress, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the balance of target values \n",
    "\n",
    "asian_sample['linked_progress'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    936\n",
       "1     50\n",
       "Name: linked_hurt, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asian_sample['linked_hurt'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    888\n",
       "1    120\n",
       "Name: linked_progress, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "black_sample['linked_progress'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    878\n",
       "1    130\n",
       "Name: linked_hurt, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "black_sample['linked_hurt'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the number of labeled Asian American articles was reduced because I removed 22 duplicate observations from the original sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove special characters, punctuations, whitespace, and stopwords\n",
    "\n",
    "- I created a function for cleaning texts.\n",
    "- Removing stop words did not increase performance in this case. (So, I commented it out.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# stop_words = stopwords.words('english')\n",
    "\n",
    "def clean_text(document):\n",
    "    document = document.str.lower() # lower case\n",
    "    document = document.str.replace('[\\r?\\n]','', regex = True)\n",
    "    document = document.str.replace('[^\\\\w\\\\s]','', regex = True)\n",
    "    document = document.str.replace('\\\\d+', '', regex = True)   \n",
    "    document = document.str.strip() # remove whitespace\n",
    "  #  document = document.apply(lambda x: \" \".join([y for y in x.split() if y not in stop_words]))\n",
    "    return(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the function works using one sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    friday nov  at  pm rev l s rubin pastor at oli...\n",
       "1    we have a large building an ante bellum buildi...\n",
       "2    ktvus televoters were back to being pretty upt...\n",
       "3    washington dc  washingtons appointed mayor wal...\n",
       "4    spokesmen for the congress of racial equality ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(black_sample['text']).head() # first 5 rows "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function to each corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seen\n",
    "\n",
    "asian_sample['text'] = clean_text(asian_sample['text'])\n",
    "black_sample['text'] = clean_text(black_sample['text'])\n",
    "\n",
    "# Unseen\n",
    "\n",
    "asian_unlabeled['text'] = clean_text(asian_unlabeled['text'])\n",
    "black_unlabeled['text'] = clean_text(black_unlabeled['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "Here, we turn texts into a document-term matrix. These terms represent features in the model and we aim to find a combination of features that are most effective in predicting target values.\n",
    "\n",
    "### Vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Bag of Words (BOW)\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    max_features = 5000, # 5,000 is large enough\n",
    "    min_df = 1, # minimum frequency 1 \n",
    "    ngram_range = (1,2), # ngram \n",
    "    binary = True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots of things happened here. \n",
    "\n",
    "- Resampling to correct the imbalanced classes: `upsampled` the minority class \n",
    "- Converting text into a `document-term matrix` \n",
    "- Splitting the matrix into the training and testing set using `stratified random sampling`\n",
    "\n",
    "I created two functions to examine the extent to which resampling improves model performances. The `dtm_train function` does not resample the data and the `dtm_train_resample function` does. I ran both functions using the same data and compared their relative performances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 1: Creating DTM and Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dtm_train(data, text, column, year):\n",
    "    \n",
    "    ############################### DOCUMENT-TERM MATRIX ################################\n",
    "    \n",
    "    # BOW model \n",
    "    \n",
    "    features = vectorizer.fit_transform(data[text]).todense() # Turn into a sparse matrix    \n",
    "\n",
    "    # Response variable\n",
    "    \n",
    "    response = data[column].values # values \n",
    "\n",
    "    ############################### STRATIFIED RANDOM SAMPLING ################################\n",
    "    \n",
    "    # Split into training and testing sets \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, response, \n",
    "                                                        test_size = 0.4, # training = 60%, test = 40%\n",
    "                                                        random_state = 1234, # for reproducibility\n",
    "                                                        stratify = data[year]) # stratifying by year\n",
    "    \n",
    "    # Label encode (normalize) response variable\n",
    "    \n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    \n",
    "    y_train = encoder.fit_transform(y_train)\n",
    "    y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "    return(X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 2: Creating DTM and Splitting data + Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def dtm_train_resample(data, text, column, year):\n",
    "    \n",
    "    ############################### RESAMPLING ################################\n",
    "    \n",
    "    # Split into majority and minority classes: # I adapted some code from here: https://elitedatascience.com/imbalanced-classes \n",
    "       \n",
    "    df_majority = data[data[column] == 0]\n",
    "    df_minority = data[data[column] == 1]\n",
    "    \n",
    "    # Upsample (oversample) minority class \n",
    "    \n",
    "    df_minority_upsampled = resample(df_minority, \n",
    "                                 replace = True,     # sample with replacement\n",
    "                                 n_samples = 400,    # to match majority class\n",
    "                                 random_state = 1234) # reproducible results\n",
    "    \n",
    "    # Combine majority class with upsampled minority class\n",
    "    data = pd.concat([df_majority, df_minority_upsampled])\n",
    "    \n",
    "    ############################### DOCUMENT-TERM MATRIX ################################\n",
    "    \n",
    "    # BOW model \n",
    "    \n",
    "    features = vectorizer.fit_transform(data[text]).todense() # Turn into a sparse matrix    \n",
    "\n",
    "    # Response variable\n",
    "    \n",
    "    response = data[column].values # values \n",
    "\n",
    "    ############################### STRATIFIED RANDOM SAMPLING ################################\n",
    "    \n",
    "    # Split into training and testing sets \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, response, \n",
    "                                                        test_size = 0.3, # training = 70%, test = 30%\n",
    "                                                        random_state = 1234, # for reproducibility\n",
    "                                                        stratify = data[year]) # stratifying by year\n",
    "    \n",
    "    # Label encode (normalize) response variable\n",
    "    \n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    \n",
    "    y_train = encoder.fit_transform(y_train)\n",
    "    y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "    return(X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Training and testing data and response variables\n",
    "\n",
    "I created training and testing data (text features) and their response variables using the two custom functions shown above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Asian American newspapers \n",
    "\n",
    "## None \n",
    "\n",
    "asian_lp_dtm = dtm_train(asian_sample, 'text', 'linked_progress', 'year')\n",
    "asian_lh_dtm = dtm_train(asian_sample, 'text', 'linked_hurt', 'year')\n",
    "\n",
    "## Resampled \n",
    "\n",
    "asian_lp_dtm_resample = dtm_train_resample(asian_sample, 'text', 'linked_progress', 'year')\n",
    "asian_lh_dtm_resample = dtm_train_resample(asian_sample, 'text', 'linked_hurt', 'year')\n",
    "\n",
    "# African American newspapers\n",
    "\n",
    "## None \n",
    "\n",
    "black_lp_dtm = dtm_train(black_sample, 'text', 'linked_progress', 'year')\n",
    "black_lh_dtm = dtm_train(black_sample, 'text', 'linked_hurt', 'year')\n",
    "\n",
    "## Resampled \n",
    "\n",
    "black_lp_dtm_resample = dtm_train_resample(black_sample, 'text', 'linked_progress', 'year')\n",
    "black_lh_dtm_resample = dtm_train_resample(black_sample, 'text', 'linked_hurt', 'year')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and evaluate a ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for various ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso\n",
    "\n",
    "def fit_logistic_regression(X_train, y_train):\n",
    "    model = LogisticRegression(fit_intercept = True,\n",
    "                               penalty = 'l1', # Lasso \n",
    "                               solver = 'saga') # for faster algorithm\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Naive-Bayes \n",
    "\n",
    "def fit_bayes(X_train, y_train):\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Xgboost\n",
    "\n",
    "def fit_xgboost(X_train, y_train):\n",
    "    model = XGBClassifier(random_state = 42,\n",
    "                         seed = 2, \n",
    "                         colsample_bytree = 0.6,\n",
    "                         subsample = 0.7)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for evaluating ML models (accuracy and balanced accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_model(model, X_train, y_train, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "#    print(\"Accuracy:\", accuracy, \"\\n\"\n",
    "#          \"Balanced accuracy:\", balanced_accuracy)\n",
    "    return(accuracy, balanced_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fitting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for fitting selected models to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_models(data):\n",
    "    # Lasso\n",
    "    lasso = fit_logistic_regression(data[0], data[1])\n",
    "    # Naive-Bayes\n",
    "    bayes = fit_bayes(data[0], data[1])\n",
    "    # Xgboost\n",
    "    xgboost = fit_xgboost(data[0], data[1])\n",
    "    \n",
    "    return(lasso, bayes, xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Asian American newspapers\n",
    "\n",
    "asian_lp_fit = fit_models(asian_lp_dtm)\n",
    "asian_lh_fit = fit_models(asian_lh_dtm)\n",
    "\n",
    "# African American newspapers\n",
    "\n",
    "black_lp_fit = fit_models(black_lp_dtm)\n",
    "black_lh_fit = fit_models(black_lh_dtm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Resampled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Asian American newspapers\n",
    "\n",
    "asian_lp_fit_resample = fit_models(asian_lp_dtm_resample)\n",
    "asian_lh_fit_resample = fit_models(asian_lh_dtm_resample)\n",
    "\n",
    "# African American newspapers\n",
    "\n",
    "black_lp_fit_resample = fit_models(black_lp_dtm_resample)\n",
    "black_lh_fit_resample = fit_models(black_lh_dtm_resample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for testing multiple models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_models(models, data):\n",
    "    lasso = test_model(models[0], data[0], data[1], data[2], data[3]) \n",
    "    bayes = test_model(models[1], data[0], data[1], data[2], data[3])\n",
    "    xgboost = test_model(models[2], data[0], data[1], data[2], data[3])\n",
    "    return(lasso, bayes, xgboost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate multiple models for each data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asian American newspapers\n",
    "\n",
    "asian_lp_models = test_models(asian_lp_fit, asian_lp_dtm)\n",
    "asian_lp_models_resample = test_models(asian_lp_fit_resample, asian_lp_dtm_resample)\n",
    "\n",
    "asian_lh_models = test_models(asian_lh_fit, asian_lh_dtm)\n",
    "asian_lh_models_resample = test_models(asian_lh_fit_resample, asian_lh_dtm_resample)\n",
    "\n",
    "# African American nespapers\n",
    "\n",
    "black_lp_models = test_models(black_lp_fit, black_lp_dtm)\n",
    "black_lp_models_resample = test_models(black_lp_fit_resample, black_lp_dtm_resample)\n",
    "\n",
    "black_lh_models = test_models(black_lh_fit, black_lh_dtm)\n",
    "black_lh_models_resample = test_models(black_lh_fit_resample, black_lh_dtm_resample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for putting the model evaluations into a table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eval_table(data):\n",
    "    table = pd.DataFrame(list(data), columns= ['Accuracy','Balanced Accuracy'])\n",
    "    table.insert(loc = 0, column = 'Models', value = ['Lasso', 'Bayes', 'Xgboost'])\n",
    "    return(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.934177</td>\n",
       "      <td>0.535678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bayes</td>\n",
       "      <td>0.931646</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xgboost</td>\n",
       "      <td>0.931646</td>\n",
       "      <td>0.517160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Models  Accuracy  Balanced Accuracy\n",
       "0    Lasso  0.934177           0.535678\n",
       "1    Bayes  0.931646           0.500000\n",
       "2  Xgboost  0.931646           0.517160"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_table(asian_lp_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.986761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bayes</td>\n",
       "      <td>0.997475</td>\n",
       "      <td>0.995690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xgboost</td>\n",
       "      <td>0.994949</td>\n",
       "      <td>0.993904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Models  Accuracy  Balanced Accuracy\n",
       "0    Lasso  0.984848           0.986761\n",
       "1    Bayes  0.997475           0.995690\n",
       "2  Xgboost  0.994949           0.993904"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_table(asian_lp_models_resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.886139</td>\n",
       "      <td>0.556917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bayes</td>\n",
       "      <td>0.888614</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xgboost</td>\n",
       "      <td>0.876238</td>\n",
       "      <td>0.502755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Models  Accuracy  Balanced Accuracy\n",
       "0    Lasso  0.886139           0.556917\n",
       "1    Bayes  0.888614           0.500000\n",
       "2  Xgboost  0.876238           0.502755"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_table(black_lp_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.935401</td>\n",
       "      <td>0.924077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bayes</td>\n",
       "      <td>0.935401</td>\n",
       "      <td>0.920125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xgboost</td>\n",
       "      <td>0.940568</td>\n",
       "      <td>0.923986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Models  Accuracy  Balanced Accuracy\n",
       "0    Lasso  0.935401           0.924077\n",
       "1    Bayes  0.935401           0.920125\n",
       "2  Xgboost  0.940568           0.923986"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_table(black_lp_models_resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# None \n",
    "\n",
    "eval_table(asian_lp_models).to_csv(\"/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/asian_lp_models.csv\")\n",
    "eval_table(asian_lh_models).to_csv(\"/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/asian_lh_models.csv\")\n",
    "\n",
    "eval_table(black_lp_models).to_csv(\"/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/black_lp_models.csv\")\n",
    "eval_table(black_lh_models).to_csv(\"/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/black_lh_models.csv\")\n",
    "\n",
    "# Resampled \n",
    "\n",
    "eval_table(asian_lp_models_resample).to_csv(\"/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/asian_lp_models_resample.csv\")\n",
    "eval_table(asian_lh_models_resample).to_csv(\"/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/asian_lh_models_resample.csv\")\n",
    "\n",
    "eval_table(black_lp_models_resample).to_csv(\"/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/black_lp_models_resample.csv\")\n",
    "eval_table(black_lh_models_resample).to_csv(\"/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/black_lh_models_resample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "### Function for predicting the unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_text(text, model):   \n",
    "      \n",
    "    # BOW model \n",
    "    \n",
    "    features = vectorizer.fit_transform(text).todense()\n",
    "    \n",
    "    # Prediction\n",
    "    \n",
    "    preds = model.predict(features)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label the unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asian Americans \n",
    "\n",
    "asian_lp_full = test_text(asian_unlabeled['text'], asian_lp_fit[0])\n",
    "asian_lh_full = test_text(asian_unlabeled['text'], asian_lh_fit[0])\n",
    "\n",
    "# African Americans \n",
    "\n",
    "black_lp_full = test_text(black_unlabeled['text'], black_lp_fit[0])\n",
    "black_lh_full = test_text(black_unlabeled['text'], black_lh_fit[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the number of observations for each class in the unlabeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4348 1807\n",
      "9329 16538\n"
     ]
    }
   ],
   "source": [
    "print(sum(asian_lp_full), sum(asian_lh_full))\n",
    "\n",
    "print(sum(black_lp_full), sum(black_lh_full))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export classification results as CSV files \n",
    "\n",
    "I saved the classification results as CSV files to plot them in R. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Rename new columns  \n",
    "\n",
    "asian_lp_data = pd.DataFrame(asian_lp_full).rename(columns = {0:'labeled_linked_progress'})\n",
    "asian_lh_data = pd.DataFrame(asian_lh_full).rename(columns = {0:'labeled_linked_hurt'})\n",
    "black_lp_data = pd.DataFrame(black_lp_full).rename(columns = {0:'labeled_linked_progress'})\n",
    "black_lh_data = pd.DataFrame(black_lh_full).rename(columns = {0:'labeled_linked_hurt'})\n",
    "\n",
    "# Save data \n",
    "\n",
    "asian_lp_data.to_csv(\"/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/asian_lp_data.csv\")\n",
    "asian_lh_data.to_csv(\"/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/asian_lh_data.csv\")\n",
    "black_lp_data.to_csv(\"/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/black_lp_data.csv\")\n",
    "black_lh_data.to_csv(\"/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/black_lh_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what the final data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labeled_linked_progress</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labeled_linked_progress\n",
       "0                        1\n",
       "1                        1\n",
       "2                        0\n",
       "3                        0\n",
       "4                        1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asian_lp_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
