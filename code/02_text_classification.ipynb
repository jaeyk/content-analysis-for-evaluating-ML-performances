{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries \n",
    "\n",
    "\n",
    "Import only relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/jae/anaconda3/lib/python3.6/site-packages (3.4.1)\r\n",
      "Requirement already satisfied: six in /home/jae/.local/lib/python3.6/site-packages (from nltk) (1.13.0)\r\n"
     ]
    }
   ],
   "source": [
    "# Numpy and Pandas \n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Data visualization \n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# REGEX and NLP\n",
    "\n",
    "import re\n",
    "import string\n",
    "!pip install nltk\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# ML\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB # Naive-Bayes\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression # Linear models\n",
    "from xgboost import XGBClassifier # XG Boost\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score # Accuracy score\n",
    "from sklearn.metrics import balanced_accuracy_score # Balanced accuracy score\n",
    "from sklearn.metrics import cohen_kappa_score # Cohen's Kappa score\n",
    "from sklearn.utils import resample # for resampling\n",
    "\n",
    "# Interface\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file path\n",
    "\n",
    "# root = tk.Tk()\n",
    "# root.withdraw()\n",
    "\n",
    "# file_path = filedialog.askopenfilename()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The labeled data \n",
    "\n",
    "asian_sample = pd.read_csv(\"/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/sample_asian.csv\")\n",
    "black_sample = pd.read_csv(\"/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/sample_black.csv\")\n",
    "\n",
    "# The unlabeled data\n",
    "\n",
    "asian_unlabeled = pd.read_csv(\"/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/unlabeled_asian.csv\")\n",
    "black_unlabeled = pd.read_csv(\"/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/unlabeled_black.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First five rows\n",
    "\n",
    "asian_sample.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select only relevant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the first column\n",
    "\n",
    "## Seen \n",
    "\n",
    "asian_sample = asian_sample.drop(['Unnamed: 0'], axis = 1)\n",
    "black_sample = black_sample.drop(['Unnamed: 0'], axis = 1)\n",
    "\n",
    "# An alternative way of doing this is asian_sample = asian_sample[['col1', 'col2']] \n",
    "\n",
    "## Unseen \n",
    "\n",
    "asian_unlabeled = asian_unlabeled.drop(['Unnamed: 0'], axis = 1)\n",
    "black_unlabeled = black_unlabeled.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert date column into datetime. This new data type allows us to extract some info from the column. For instance, `asian_samplep['date'].year` returns years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Seen data \n",
    "asian_sample[\"date\"] = pd.to_datetime(asian_sample[\"date\"])\n",
    "black_sample[\"date\"] = pd.to_datetime(black_sample[\"date\"])\n",
    "\n",
    "# Unseen data \n",
    "asian_unlabeled[\"date\"] = pd.to_datetime(asian_unlabeled[\"date\"])\n",
    "black_unlabeled[\"date\"] = pd.to_datetime(black_unlabeled[\"date\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the balance of target values: **imbalanced**. I used a resampling method (upsampling/oversampling) to address this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the balance of target values \n",
    "\n",
    "asian_sample['linked_progress'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asian_sample['linked_hurt'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_sample['linked_progress'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_sample['linked_hurt'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the number of labeled Asian American articles was reduced as I remove 18 duplicates from the original sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove special characters, punctuations, whitespace, and stopwords\n",
    "\n",
    "- I created a function for cleaning texts.\n",
    "- Removing stop words did not increase performance in this case. (So, I commented it out.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# stop_words = stopwords.words('english')\n",
    "\n",
    "def clean_text(document):\n",
    "    document = document.str.lower() # lower case\n",
    "    document = document.str.replace('[\\r?\\n]','', regex = True)\n",
    "    document = document.str.replace('[^\\\\w\\\\s]','', regex = True)\n",
    "    document = document.str.replace('\\\\d+', '', regex = True)   \n",
    "    document = document.str.strip() # remove whitespace\n",
    "  #  document = document.apply(lambda x: \" \".join([y for y in x.split() if y not in stop_words]))\n",
    "    return(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how it works using one sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text(black_sample['text']).head() # first 5 rows "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function to each corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seen\n",
    "\n",
    "asian_sample['text'] = clean_text(asian_sample['text'])\n",
    "black_sample['text'] = clean_text(black_sample['text'])\n",
    "\n",
    "# Unseen\n",
    "\n",
    "asian_unlabeled['text'] = clean_text(asian_unlabeled['text'])\n",
    "black_unlabeled['text'] = clean_text(black_unlabeled['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "Here, we turn texts into a document-term matrix. These terms represent features in the model and we aim to find a combination of features that are most effective in predicting target values.\n",
    "\n",
    "### Vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Bag of Words (BOW)\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    max_features = 5000, # 5,000 is large enough\n",
    "    min_df = 1, # minimum frequency 1 \n",
    "    ngram_range = (1,2), # ngram \n",
    "    binary = True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots of things happened here. \n",
    "\n",
    "- Resampling to correct the imbalanced classes: `upsampled` the minority class \n",
    "- Converting text into a `document-term matrix` \n",
    "- Splitting the matrix into the training and testing set using `stratified random sampling`\n",
    "\n",
    "I created two functions to examine how resampling improves model performances. The `dtm_train function` does not resample the data and the `dtm_train_resample function` did. I ran both functions using the same data and compare how these two performed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 1: Creating DTM and Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dtm_train(data, text, column, year):\n",
    "    \n",
    "    ############################### DOCUMENT-TERM MATRIX ################################\n",
    "    \n",
    "    # BOW model \n",
    "    \n",
    "    features = vectorizer.fit_transform(data[text]).todense() # Turn into a sparse matrix    \n",
    "\n",
    "    # Response variable\n",
    "    \n",
    "    response = data[column].values # values \n",
    "\n",
    "    ############################### STRATIFIED RANDOM SAMPLING ################################\n",
    "    \n",
    "    # Split into training and testing sets \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, response, \n",
    "                                                        test_size = 0.2, # training = 80%, test = 20%\n",
    "                                                        random_state = 1234, # for reproducibility\n",
    "                                                        stratify = data[year]) # stratifying by year\n",
    "    \n",
    "    # Label encode (normalize) response variable\n",
    "    \n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    \n",
    "    y_train = encoder.fit_transform(y_train)\n",
    "    y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "    return(X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 2: Creating DTM and Splitting data + Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def dtm_train_resample(data, text, column, year):\n",
    "    \n",
    "    ############################### RESAMPLING ################################\n",
    "    \n",
    "    # Split into majority and minority classes: # I adapted some code from here: https://elitedatascience.com/imbalanced-classes \n",
    "       \n",
    "    df_majority = data[data[column] == 0]\n",
    "    df_minority = data[data[column] == 1]\n",
    "    \n",
    "    # Upsample (oversample) minority class \n",
    "    \n",
    "    df_minority_upsampled = resample(df_minority, \n",
    "                                 replace = True,     # sample with replacement\n",
    "                                 n_samples = 750,    # to match majority class\n",
    "                                 random_state = 1234) # reproducible results\n",
    "    \n",
    "    # Combine majority class with upsampled minority class\n",
    "    data = pd.concat([df_majority, df_minority_upsampled])\n",
    "    \n",
    "    ############################### DOCUMENT-TERM MATRIX ################################\n",
    "    \n",
    "    # BOW model \n",
    "    \n",
    "    features = vectorizer.fit_transform(data[text]).todense() # Turn into a sparse matrix    \n",
    "\n",
    "    # Response variable\n",
    "    \n",
    "    response = data[column].values # values \n",
    "\n",
    "    ############################### STRATIFIED RANDOM SAMPLING ################################\n",
    "    \n",
    "    # Split into training and testing sets \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, response, \n",
    "                                                        test_size = 0.2, # training = 80%, test = 20%\n",
    "                                                        random_state = 1234, # for reproducibility\n",
    "                                                        stratify = data[year]) # stratifying by year\n",
    "    \n",
    "    # Label encode (normalize) response variable\n",
    "    \n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    \n",
    "    y_train = encoder.fit_transform(y_train)\n",
    "    y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "    return(X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Training and testing data and response variables\n",
    "\n",
    "I created training and testing data (text features) and their response variables using the two custom functions shown above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Asian American newspapers \n",
    "\n",
    "## None \n",
    "\n",
    "asian_lp_dtm = dtm_train(asian_sample, 'text', 'linked_progress', 'year')\n",
    "asian_lh_dtm = dtm_train(asian_sample, 'text', 'linked_hurt', 'year')\n",
    "\n",
    "## Resampled \n",
    "\n",
    "asian_lp_dtm_resample = dtm_train_resample(asian_sample, 'text', 'linked_progress', 'year')\n",
    "asian_lh_dtm_resample = dtm_train_resample(asian_sample, 'text', 'linked_hurt', 'year')\n",
    "\n",
    "# African American newspapers\n",
    "\n",
    "## None \n",
    "\n",
    "black_lp_dtm = dtm_train(black_sample, 'text', 'linked_progress', 'year')\n",
    "black_lh_dtm = dtm_train(black_sample, 'text', 'linked_hurt', 'year')\n",
    "\n",
    "## Resampled \n",
    "\n",
    "black_lp_dtm_resample = dtm_train_resample(black_sample, 'text', 'linked_progress', 'year')\n",
    "black_lh_dtm_resample = dtm_train_resample(black_sample, 'text', 'linked_hurt', 'year')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and evaluate a ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for various ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso\n",
    "\n",
    "def fit_logistic_regression(X_train, y_train):\n",
    "    model = LogisticRegression(fit_intercept = True, penalty = 'l1', solver = 'saga') # Lasso\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Naive-Bayes \n",
    "\n",
    "def fit_bayes(X_train, y_train):\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# XG Boost \n",
    "\n",
    "def fit_xgboost(X_train, y_train):\n",
    "    model = XGBClassifier(random_state = 42,\n",
    "                         seed = 2, \n",
    "                         colsample_bytree = 0.6,\n",
    "                         subsample = 0.7)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for evaluating ML models (accuracy, balanced accuracy, and Cohen's kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_model(model, X_train, y_train, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "    kappa = cohen_kappa_score(y_test, y_pred)\n",
    "#    print(\"Accuracy:\", accuracy, \"\\n\"\n",
    "#          \"Balanced accuracy:\", balanced_accuracy, \"\\n\"\n",
    "#          \"Cohen's Kappa:\", kappa)\n",
    "    return(accuracy, balanced_accuracy, kappa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fitting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for fitting selected models to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_models(data):\n",
    "    # Lasso\n",
    "    lasso = fit_logistic_regression(data[0], data[1])\n",
    "    # Naive-Bayes\n",
    "    bayes = fit_bayes(data[0], data[1])\n",
    "    # XG Boost\n",
    "    xgboost = fit_bayes(data[0], data[1])\n",
    "    \n",
    "    return(lasso, bayes, xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Asian American newspapers\n",
    "\n",
    "asian_lp_fit = fit_models(asian_lp_dtm)\n",
    "asian_lh_fit = fit_models(asian_lh_dtm)\n",
    "\n",
    "# African American newspapers\n",
    "\n",
    "black_lp_fit = fit_models(black_lp_dtm)\n",
    "black_lh_fit = fit_models(black_lh_dtm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Resampled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Asian American newspapers\n",
    "\n",
    "asian_lp_fit_resample = fit_models(asian_lp_dtm_resample)\n",
    "asian_lh_fit_resample = fit_models(asian_lh_dtm_resample)\n",
    "\n",
    "# African American newspapers\n",
    "\n",
    "black_lp_fit_resample = fit_models(black_lp_dtm_resample)\n",
    "black_lh_fit_resample = fit_models(black_lh_dtm_resample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for testing multiple models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_models(models, data):\n",
    "    lasso = test_model(models[0], data[0], data[1], data[2], data[3])\n",
    "    bayes = test_model(models[1], data[0], data[1], data[2], data[3])\n",
    "    xgboost = test_model(models[2], data[0], data[1], data[2], data[3])\n",
    "    return(lasso, bayes, xgboost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate multiple models for each data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asian American newspapers\n",
    "\n",
    "asian_lp_models = test_models(asian_lp_fit, asian_lp_dtm)\n",
    "asian_lp_models_sample = test_models(asian_lp_fit_resample, asian_lp_dtm_resample)\n",
    "\n",
    "asian_lh_models = test_models(asian_lh_fit, asian_lh_dtm)\n",
    "asian_lh_models_sample = test_models(asian_lh_fit_resample, asian_lh_dtm_resample)\n",
    "\n",
    "# African American nespapers\n",
    "\n",
    "black_lp_models = test_models(black_lp_fit, black_lp_dtm)\n",
    "black_lp_models_sample = test_models(black_lp_fit_resample, black_lp_dtm_resample)\n",
    "\n",
    "black_lh_models = test_models(black_lh_fit, black_lh_dtm)\n",
    "black_lh_models_sample = test_models(black_lh_fit_resample, black_lh_dtm_resample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "### Function for predicting the unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_text(text, model):   \n",
    "      \n",
    "    # BOW model \n",
    "    \n",
    "    features = vectorizer.fit_transform(text).todense()\n",
    "    \n",
    "    # Prediction\n",
    "    \n",
    "    preds = model.predict(features)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label the unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asian Americans \n",
    "\n",
    "# asian_lp_full = test_text(asian_unlabeled['text'], asian_lp)\n",
    "# asian_lh_full = test_text(asian_unlabeled['text'], asian_lh)\n",
    "\n",
    "# African Americans \n",
    "\n",
    "# black_lp_full = test_text(black_unlabeled['text'], black_lp)\n",
    "# black_lh_full = test_text(black_unlabeled['text'], black_lh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export classification results as CSV files \n",
    "\n",
    "I saved the classification results as CSV files to plot them in R. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Rename new columns  \n",
    "\n",
    "# asian_lp_data = pd.DataFrame(asian_lp_full).rename(columns = {0:'labeled_linked_progress'})\n",
    "# asian_lh_data = pd.DataFrame(asian_lh_full).rename(columns = {0:'labeled_linked_hurt'})\n",
    "# black_lp_data = pd.DataFrame(black_lp_full).rename(columns = {0:'labeled_linked_progress'})\n",
    "# black_lh_data = pd.DataFrame(black_lh_full).rename(columns = {0:'labeled_linked_hurt'})\n",
    "\n",
    "# Save data \n",
    "\n",
    "# asian_lp_data.to_csv(\"/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/asian_lp_data.csv\")\n",
    "# asian_lh_data.to_csv(\"/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/asian_lh_data.csv\")\n",
    "# black_lp_data.to_csv(\"/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/black_lp_data.csv\")\n",
    "# black_lh_data.to_csv(\"/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/black_lh_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what the final data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asian_lp_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
