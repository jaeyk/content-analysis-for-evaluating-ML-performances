---
title: "Comparing the results"
author: "Jae Yeon Kim"
output:
html_document:
  toc: True
  theme: united
  number_sections: True
---

# Setup 

```{r include=FALSE}

pacman::p_load(
        tidyverse, # for the tidyverse framework
        irr, # for calculating inter-coder reliability score
        corrplot, # for visualizing correlation coefficients
        ggpubr, # for arranging ggplots 
        ggthemes, # for fancy ggplot themes
        furrr, # for multiprocessing
        pglm, # for panel estimators for generalized linear models
        glmmML, # for longitudinal logit modeling 
        survival, # for longitudinal logit modeling
        lme4, # for fitting generalized linear mixed-effects models
        lmtest, # for testing linear regression models
        stargazer, # for model outputs 
        boot, # for bootstrapping 
        broom, # for tidying model outcomes 
        rsample # for tidy bootstrapping
)

# devtools::install_github("jaeyk/makereproducible")
library(makereproducible)

# Import R scripts

script_list <- list.files(paste0(here::here(), "/functions"),
  pattern = "*.r|*.R",
  full.names = TRUE
)


for (i in 1:length(script_list))
{
  source(script_list[[i]])
}

# for publication-friendly theme
theme_set(theme_pubr())
```

# Import files 

```{r include=FALSE}

full_articles <- read_csv(make_here("/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/full_articles.csv"))

full_articles_gran <- read_csv(make_here("/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/full_articles_gran.csv"))

# Training data for classifying articles from African American newspapers
training_black <- read_csv(make_here("/home/jae/content-analysis-for-evaluating-ML-performances/raw_data/training_black.csv")) %>%
  dplyr::select(-contains("Notes")) %>%
  mutate(linked_progress_gran = ifelse(Promoting_collective_gains_A + Promoting_collective_gains_B >= 1, 1, 0),
         linked_hurt_gran = ifelse(Preventing_collective_losses_A + Preventing_collective_losses_B >= 1, 1, 0),
         linked_progress = ifelse(Promoting_collective_gains_A + Promoting_collective_gains_B == 2, 1, 0),
         linked_hurt = ifelse(Preventing_collective_losses_A + Preventing_collective_losses_B == 2, 1, 0))

training_asian <- read_csv(make_here("/home/jae/content-analysis-for-evaluating-ML-performances/raw_data/training_asian.csv")) %>%
  dplyr::select(-contains("Notes")) %>%
  mutate(linked_progress_gran = ifelse(Promoting_collective_gains_A + Promoting_collective_gains_B >= 1, 1, 0),
         linked_hurt_gran = ifelse(Preventing_collective_losses_A + Preventing_collective_losses_B >= 1, 1, 0),
         linked_progress = ifelse(Promoting_collective_gains_A + Promoting_collective_gains_B == 2, 1, 0),
         linked_hurt = ifelse(Preventing_collective_losses_A + Preventing_collective_losses_B == 2, 1, 0))

```

# Merge data 

```{r}

df <- bind_rows(mutate(full_articles, type = "Maximum"),
                mutate(full_articles_gran, type = "Minimum")) %>%
                mutate(group = factor(group, levels =c("Asian Americans", "African Americans")))

df_sample <- bind_rows(
  mutate(training_asian, group = "Asian Americans"),
  mutate(training_black, group = "African Americans")) %>%
  mutate(lp_exclusive = ifelse(linked_progress == 1 & linked_hurt == 0, 1, 0), type = "Maximum") %>%
  mutate(lh_exclusive = ifelse(linked_progress == 0 & linked_hurt == 1, 1, 0), type = "Maximum") %>%
  mutate(lf_mixed = ifelse(linked_progress == 1 & linked_hurt == 1, 1, 0), type = "Maximum")

df_sample <- bind_rows(df_sample, 
df_sample %>%
  mutate(lp_exclusive = ifelse(linked_progress_gran == 1 & linked_hurt_gran == 0, 1, 0), type = "Minimum") %>%
  mutate(lh_exclusive = ifelse(linked_progress_gran == 0 & linked_hurt_gran == 1, 1, 0), type = "Minimum") %>%
  mutate(lf_mixed = ifelse(linked_progress_gran == 1 & linked_hurt_gran == 1, 1, 0), type = "Minimum"))

```

# Visualize data 

## Content vs. Classification 

```{r}

df_sample$group <- factor(df_sample$group, levels = c("Asian Americans", "African Americans"))

content <- df_sample %>%
  gather(linked_fate, value, lp_exclusive, lh_exclusive, lf_mixed) %>%
  filter(linked_fate != "lf_mixed") %>%
  group_by(group, linked_fate, type) %>%
  summarize(mean = round(mean(value),2),
            sd  = sd(value),
            n = n()) %>%
  mutate(se = sd / sqrt(n), # calculate standard errors and confidence intervals 
         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,
         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se) %>%
  ggplot(aes(x = fct_reorder(type, mean), y = mean, fill = linked_fate)) +
    geom_bar(stat="identity", color="black", 
             position=position_dodge()) +
    geom_errorbar(aes(ymin= lower.ci, ymax = upper.ci), width=.2,
                   position=position_dodge(.9)) +
    facet_wrap(~group) +
    scale_fill_manual(name = "Type", labels = c("Collective loss","Collective gain"), values=c("red","blue")) +
    scale_y_continuous(labels = scales::percent_format(accuracy = 5L)) +
    geom_text(aes(label = paste(mean*100, "%")), position=position_dodge(width=0.9), vjust=-1.5) +
    labs(title = "Content analysis", y = "Proportion of articles", x = "Group") 

classification <- df %>%
  gather(linked_fate, value, lp_exclusive, lh_exclusive, lf_mixed) %>%
  filter(linked_fate != "lf_mixed") %>%
  group_by(group, linked_fate, type) %>%
  summarize(mean = round(mean(value),2),
            sd  = sd(value),
            n = n()) %>%
  mutate(se = sd / sqrt(n), # calculate standard errors and confidence intervals 
         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,
         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se) %>%
  ggplot(aes(x = fct_reorder(type, mean), y = mean, fill = linked_fate)) +
    geom_bar(stat="identity", color="black", 
             position=position_dodge()) +
    geom_errorbar(aes(ymin= lower.ci, ymax = upper.ci), width=.2,
                   position=position_dodge(.9)) +
    facet_wrap(~group) +
    scale_fill_manual(name = "Type", labels = c("Collective loss","Collective gain"), values=c("red","blue")) +
    scale_y_continuous(labels = scales::percent_format(accuracy = 5L)) +
    geom_text(aes(label = paste(mean*100, "%")), position=position_dodge(width=0.9), vjust=-1.5) +
    labs(title = "Automated text classification", y = "Proportion of articles", x = "Group")

ggarrange(content, classification, common.legend = TRUE)

ggsave(make_here("/home/jae/content-analysis-for-evaluating-ML-performances/outputs/content_classification.png"), height = 7, width = 13)

```

## Experimentation 

```{r}

df %>%
  group_by(group, type, year) %>%
  sample_n(size = 100) %>%
    gather(linked_fate, value, lp_exclusive, lh_exclusive, lf_mixed) %>%
  filter(linked_fate != "lf_mixed") %>%
  group_by(group, linked_fate, type) %>%
  summarize(mean = round(mean(value),2),
            sd  = sd(value),
            n = n()) %>%
  mutate(se = sd / sqrt(n), # calculate standard errors and confidence intervals 
         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,
         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se) %>%
  ggplot(aes(x = fct_reorder(type, mean), y = mean, fill = linked_fate)) +
    geom_bar(stat="identity", color="black", 
             position=position_dodge()) +
    geom_errorbar(aes(ymin= lower.ci, ymax = upper.ci), width=.2,
                   position=position_dodge(.9)) +
    facet_wrap(~group) +
    scale_fill_manual(name = "Type", labels = c("Collective loss","Collective gain"), values=c("red","blue")) +
    scale_y_continuous(labels = scales::percent_format(accuracy = 5L)) +
    geom_text(aes(label = paste(mean*100, "%")), position=position_dodge(width=0.9), vjust=-1.5) +
    labs(title = "Automated text classification", y = "Proportion of articles", x = "Group")

```

## Year matched vs. unmatched 

```{r}

year_unmatched <- df %>%
  gather(linked_fate, value, lp_exclusive, lh_exclusive, lf_mixed) %>%
  filter(linked_fate != "lf_mixed") %>%
  group_by(group, linked_fate, type) %>%
  summarize(mean = round(mean(value),2),
            sd  = sd(value),
            n = n()) %>%
  mutate(se = sd / sqrt(n), # calculate standard errors and confidence intervals 
         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,
         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se) %>%
  ggplot(aes(x = fct_reorder(type, mean), y = mean, fill = linked_fate)) +
    geom_bar(stat="identity", color="black", 
             position=position_dodge()) +
    geom_errorbar(aes(ymin= lower.ci, ymax = upper.ci), width=.2,
                   position=position_dodge(.9)) +
    facet_wrap(~group) +
    scale_fill_manual(name = "Type", labels = c("Collective loss","Collective gain"), values=c("red","blue")) +
    scale_y_continuous(labels = scales::percent_format(accuracy = 5L)) +
    geom_text(aes(label = paste(mean*100, "%")), position=position_dodge(width=0.9), vjust=-1.5) +
    labs(title = "Unmatched comparison (1968-1989)", y = "Proportion of articles", x = "Group") 

year_matched <- df %>%
  gather(linked_fate, value, lp_exclusive, lh_exclusive, lf_mixed) %>%
  filter(year >= 1976 & year <= 1979) %>%
  filter(linked_fate != "lf_mixed") %>%
  group_by(group, linked_fate, type) %>%
  summarize(mean = round(mean(value),2),
            sd  = sd(value),
            n = n()) %>%
  mutate(se = sd / sqrt(n), # calculate standard errors and confidence intervals 
         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,
         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se) %>%
  ggplot(aes(x = fct_reorder(type, mean), y = mean, fill = linked_fate)) +
    geom_bar(stat="identity", color="black", 
             position=position_dodge()) +
    geom_errorbar(aes(ymin= lower.ci, ymax = upper.ci), width=.2,
                   position=position_dodge(.9)) +
    facet_wrap(~group) +
    scale_fill_manual(name = "Type", labels = c("Collective loss","Collective gain"), values=c("red","blue")) +
    scale_y_continuous(labels = scales::percent_format(accuracy = 5L)) +
    geom_text(aes(label = paste(mean*100, "%")), position=position_dodge(width=0.9), vjust=-1.5) +
    labs(title = "Matched comparison (1976-1979)", y = "Proportion of articles", x = "Group")

ggarrange(year_unmatched, year_matched, common.legend = TRUE)

ggsave(make_here("/home/jae/content-analysis-for-evaluating-ML-performances/outputs/matched_comparison_year.png"), height = 7, width = 13)

df %>%
  filter(year >= 1983 & year <= 1987) %>%
  filter(group == "Asian Americans") %>%
  group_by(type, source) %>%
  summarize(lp_mean = mean(lp_exclusive), 
            lh_mean = mean(lh_exclusive))

```
