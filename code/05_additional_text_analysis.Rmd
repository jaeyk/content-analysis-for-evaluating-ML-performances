---
html_document:
  toc: True
  theme: united
  number_sections: True
---

# Setup

```{r include=FALSE}

pacman::p_load(
        tidyverse, # for the tidyverse framework
        ggpubr, # for arranging ggplots
        ggthemes, # for fancy ggplot themes
        ggrepel, # annotating text in ggplot2 
        tidytext, # for tidytext
        furrr, # for multiprocessing
        patchwork, # for arranging images
        scales, # for scales 
        here, # reproducibility 
        drake) # pipeline

# devtools::install_github("jaeyk/makereproducible")
library(makereproducible)

# Import R scripts

script_list <- list.files(paste0(here::here(), "/functions"),
  pattern = "*.r|*.R",
  full.names = TRUE
)


for (i in 1:length(script_list))
{
  source(script_list[[i]])
}

# for publication-friendly theme
theme_set(theme_pubr())
```


# Import files

```{r}
# Maximum threshold 
full_articles <- read_csv(here("processed_data", "full_articles.csv"))

# Minimum threshold 
full_articles_gran <- read_csv(here("processed_data", "full_articles_gran.csv"))

full_articles_gran <- full_articles_gran %>%
  mutate(lp_exclusive = ifelse(linked_progress == 1 & linked_hurt == 0, 1, 0),
         lh_exclusive = ifelse(linked_progress == 0 & linked_hurt == 1, 1, 0),
         lf_mixed = ifelse(linked_progress == 1 & linked_hurt == 1, 1, 0))
```

# Relative most frequent words

```{r tidy}
# Tidy text 
tidy_articles <- tidy_text(full_articles, lp_exclusive, lh_exclusive)

tidy_articles_gran <- tidy_text(full_articles_gran, lp_exclusive, lh_exclusive)

write_csv(tidy_articles, here("processed_data", "tidy_articles.csv"))

write_csv(tidy_articles_gran, here("processed_data", "tidy_articles_gran.csv"))

```

```{r tokenize}
tidy_articles <- data.table::fread(here("processed_data", "tidy_articles.csv"))

tidy_articles_gran <- data.table::fread(here("processed_data", "tidy_articles_gran.csv"))

# Tokenize text 

tokenized_articles <- tokenize_text(tidy_articles)

tokenized_articles_gran <- tokenize_text(tidy_articles_gran)

```

```{r}

# Count word frequency 

wf <- create_word_frequency(tokenized_articles, 20, 20)

wf_gran <- create_word_frequency(tokenized_articles_gran, 20, 20)

write_csv(word_frequency, here("processed_data", "word_frequency.csv"))

write_csv(tidy_articles_gran, here("processed_data", "word_frequency_gran.csv"))

```

```{r}

# Visualize 

wf_plot <- visualize_wf(wf) + labs(title = "Maximum threshold")

wf_gran_plot <- visualize_wf(wfg) + labs(title = "Minimum threshold")

wf_plot 

ggsave(here("outputs", "relative_word_freq.png"), width = 12, height = 12)

wf_gran_plot

ggsave(here("outputs", "relative_word_freq_gran.png"), width = 12, height = 12)

```