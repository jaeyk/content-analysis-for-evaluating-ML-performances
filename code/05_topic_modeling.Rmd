---
title: "Topic modeling analysis"
author: "Jae Yeon Kim"
output:
html_document:
  toc: true
  theme: united
---

# Setup

## 0. Setup

```{r}

# Clean up the environment

rm(list = ls())

# Import libraries (adapted from this link: https://stackoverflow.com/questions/4090169/elegant-way-to-check-for-missing-packages-and-install-them)

if (!require("pacman")) install.packages("pacman")
pacman::p_load(
        tidyverse, # for the tidyverse framework
        irr, # for calculating inter-coder reliability score
        corrplot, # for visualizing correlation coefficients
        ggpubr, # for arranging ggplots
        ggthemes, # for fancy ggplot themes
        tidytext, # for tidytext
        stm, # for structural topic modeling
        tidystm, # for extracting estimated effects from stm
        furrr, # for multiprocessing
        patchwork, # for arranging images
        scales # for scales 
)

source("/home/jae/content-analysis-for-evaluating-ML-performances/functions/text_analysis.r")

source("/home/jae/content-analysis-for-evaluating-ML-performances/functions/theme_publications.r")

theme_set(theme_Publication(14))
```

## 1. Import files

```{r include=FALSE}

full_articles <- read_csv( "/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/full_articles.csv")

```

## 2. Clean and wrangle data

```{r}

# Manipulate strings
full_articles$source <- str_trim(gsub(".*:", "", full_articles$source))

# Dropping columns
full_articles <- full_articles %>%
  dplyr::select(-c(X1, author, linked_progress, linked_hurt, date)) 

# Subsetting
lp_articles <- full_articles %>%
  filter(lp_exclusive == 1)

lh_articles <- full_articles %>%
  filter(lh_exclusive == 1)

```

## 3. Structural topic modeling

I adapted the code from Julia Silge's [amazing STM tutotial](https://juliasilge.com/blog/evaluating-stm/).

### 3.1. Preprocessing

```{r}

# Apply clean text function to each data

lp_articles <- clean_text(lp_articles)
lh_articles <- clean_text(lh_articles)

# Create a document-term matrix

lp_articles_sparse <- create_sparse_matrix(lp_articles)
lh_articles_sparse <- create_sparse_matrix(lh_articles)

# Check (both numbers should be identical)

paste(dim(lp_articles_sparse)[1], dim(lp_articles)[1])
paste(dim(lh_articles_sparse)[1], dim(lh_articles)[1])

```

### 3.2. Train and evaluate a topic model

#### 3.2.1. Train many models

```{r include=FALSE}

plan(multiprocess)

lp_many_models <- data_frame(K = c(10:15)) %>%
  mutate(topic_model = future_map(K, ~stm(lp_articles_sparse, K = .)))

lh_many_models <- data_frame(K = c(10:15)) %>%
  mutate(topic_model = future_map(K, ~stm(lh_articles_sparse, K = .)))

```

#### 3.2.2. Visualize diagnostics

```{r}

lp_diag <- visualize_diagnostics(asian_lp_articles_sparse, lp_many_models) + labs(subtitle = "Linked progress articles") 
lh_diag <- visualize_diagnostics(black_lh_articles_sparse, lh_many_models) + labs(subtitle = "Linked hurt articles") 

lp_diag / lh_diag

ggsave("/home/jae/content-analysis-for-evaluating-ML-performances/outputs/topic_modeling_diagnosis_plot.png", height = 10)

```

### 3.3. Adding covariates

12, 10, 11, 10

```{r eval=FALSE, include=FALSE}

# Construct STM

lp_stm <- stm(documents = lp_articles_sparse,
              data = lp_articles,
              prevalence = ~group,
              K = 14)

lh_stm <- stm(documents = lh_articles_sparse,
              data = lh_articles,
              prevalence = ~group,
              K = 13)

# Save these heavy files

write_rds(lp_stm, "/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/lp_stm.rds")
write_rds(lh_stm, "/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/lh_stm.rds")

```

### 3.4. Plotting topic modeling results 

```{r}

# Read files 
lp_stm <- read_rds("/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/lp_stm.rds")
lh_stm <- read_rds("/home/jae/content-analysis-for-evaluating-ML-performances/processed_data/lh_stm.rds")

# Prep
lp_predict_topics <- estimateEffect(formula = 1:14 ~ group, stmobj = lp_stm, metadata = lp_articles, uncertainty = "Global")
lh_predict_topics <- estimateEffect(formula = 1:13 ~ group, stmobj = lh_stm, metadata = lh_articles, uncertainty = "Global")

# Plotting estimated effects

lp_predict_group <- extract.estimateEffect(lp_predict_topics, "group",
                       model = lp_stm,
                       method = "pointestimate") %>%
  ggplot(aes(x = factor(topic), y = estimate, ymax = ci.upper, ymin = ci.lower, col = covariate.value)) +
  geom_pointrange() + theme_base() +
  labs(x = "Topics",
       y = "Estimated effects",
       col = "Group",
       title = "Structural topic modeling results",
       subtitle = "Linked progress articles") +
       theme(legend.position = 'bottom') +
       ylim(c(0, 0.4))

lh_predict_group <- extract.estimateEffect(lh_predict_topics, "group",
                       model = lh_stm,
                       method = "pointestimate") %>%
  ggplot(aes(x = factor(topic), y = estimate, ymax = ci.upper, ymin = ci.lower, col = covariate.value)) +
  geom_pointrange() + theme_base() +
  labs(x = "Topics",
       y = "Estimated effects",
       col = "Group",
       title = "Structural topic modeling results",
       subtitle = "Linked hurt articles") +
       theme(legend.position = 'bottom') +
       ylim(c(0, 0.4))

lp_predict_group + lh_predict_group

ggsave("/home/jae/content-analysis-for-evaluating-ML-performances/outputs/topic_predict_estimates_plot.png", width = 12)

```
### 3.5. Content analysis

```{r}

asian_thoughts <- findThoughts(lp_stm, texts = lp_articles$text, topics = c(6, 8, 13), n = 10)

black_thoughts <- findThoughts(lh_stm, texts = lh_articles$text, topics = c(4, 13), n = 10)

black_thoughts
```

